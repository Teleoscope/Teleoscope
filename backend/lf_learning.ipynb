{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d979288c-7e14-4d92-b9de-6c2acc9571ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84f9d1b9-d81c-4c83-9c9d-30d03eab859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from bson.objectid import ObjectId\n",
    "import gc\n",
    "import tasks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numba\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b38e4ce-fefc-4ba3-b60c-b7c9ea0becfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for jupyter notebook widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac8027c-af0d-4bf3-8d06-176ced95da0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['20.220.215.35:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', authmechanism='SCRAM-SHA-256', connecttimeoutms=50000, serverselectiontimeoutms=50000, directconnection=True, replicaset='rs0'), 'aita')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to database\n",
    "db = utils.connect()\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe4861-8e82-4434-b536-fcf9541d0648",
   "metadata": {},
   "source": [
    "### Setup Human Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4448d3-9fca-44af-a4df-16718f686a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 groups from database\n"
     ]
    }
   ],
   "source": [
    "# hardcoded group id strings\n",
    "group_id_strings = ['63901a89e189962b660959cf', '63901a92931eeac91c9924a1', '63901a96e189962b660959d3']\n",
    "\n",
    "# convert to objectId's\n",
    "group_ids = [ObjectId(str(id)) for id in group_id_strings]\n",
    "\n",
    "# retrieve groups from database\n",
    "groups = list(db.groups.find({\"_id\":{\"$in\" : group_ids}}))\n",
    "print(\"Retrieved \" + str(len(groups)) + \" groups from database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8244c486-26d3-409d-b914-30eaec8a44a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hetv62', 'lwd55z', 'dhbdpv', 'eyj0sv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]['history'][0]['included_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c27a74c-e029-40a5-b0ee-c69cd123b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'textVector': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projection here to only include the fields we want\n",
    "projection = {'id': 1, 'textVector': 1}\n",
    "projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74e643-031e-4e66-a2d1-ba5c04f935df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cefb4-31cb-4b2b-9a55-79b62018e5ca",
   "metadata": {},
   "source": [
    "Options to define training set:\n",
    "1. Use the first groups teleoscope ordering\n",
    "2. Use all documents\n",
    "3. Create a new teleo vec from all documents in human clusters\n",
    "\n",
    "Embeddings\n",
    "- save training set upon creation (check if created or not)\n",
    "    - we need to save both ids and vectors for recall at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54c336-714e-42b1-94b5-24fe2b2f707e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Save & Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415165c7-d80c-4728-b3e2-f6659abe0808",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using First Group's Teleoscope Ordering\n",
    "\n",
    "Change Raw cells below to Code if you need to reload document ids / vectors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b7f4021-45dc-4cb9-b2a2-97e34f9a65f0",
   "metadata": {},
   "source": [
    "# default to ordering documents relative to first group's teleoscope\n",
    "teleoscope_oid = groups[0][\"teleoscope\"]\n",
    "teleoscope_oid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15ea38dd-41f2-4b24-8fa1-808457876294",
   "metadata": {
    "tags": []
   },
   "source": [
    "teleoscope = db.teleoscopes.find_one({\"_id\": ObjectId(str(teleoscope_oid))})\n",
    "#teleoscope"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abff2e50-b003-4f9e-a8c7-33173ad74c83",
   "metadata": {},
   "source": [
    "# saved as ordered_documents.npz\n",
    "# change to code cell if load is needed\n",
    "\n",
    "# get Teleoscope from GridFS\n",
    "all_ordered_documents = utils.gridfsDownload(db, \"teleoscopes\", ObjectId(str(teleoscope[\"history\"][0][\"ranked_document_ids\"])))\n",
    "\n",
    "# np.savez_compressed('all_ordered_documents', ord_docs=all_ordered_documents)\n",
    "# all_ordered_documents = np.load('all_ordered_documents.npz')['ord_docs']\n",
    "\n",
    "len(all_ordered_documents)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a9fca45-e956-4f1a-bb91-c899f831d225",
   "metadata": {},
   "source": [
    "# grab only subset of the ordered documents\n",
    "limit = 10000\n",
    "# TODO: does this line generate an out of bounds access?\n",
    "ordered_documents = all_ordered_documents[0:limit]\n",
    "limit = min(limit, len(ordered_documents))\n",
    "limit\n",
    "\n",
    "# cursor is a generator which means it yields a new doc one at a time\n",
    "cursor = db.documents.find(\n",
    "    # query\n",
    "    {\"id\":{\"$in\": [document[0] for document in ordered_documents]}},\n",
    "    projection=projection,\n",
    "    # batch size means number of documents at a time taken from MDB, no impact on iteration\n",
    "    batch_size=500\n",
    ")\n",
    "document_ids = []\n",
    "document_vectors = []\n",
    "\n",
    "# for large datasets, this will take a while. Would be better to find out whether the UMAP fns can \n",
    "# accept generators for lazy calculation\n",
    "for document in tqdm.tqdm(cursor, total=limit):\n",
    "    document_ids.append(document[\"id\"])\n",
    "    document_vectors.append(document[\"textVector\"])\n",
    "\n",
    "print(\"There are \" + str(len(document_ids)) + \" document ids.\")\n",
    "print(\"There are \" + str(len(document_vectors)) + \" document vectors.\")\n",
    "\n",
    "np.savez_compressed('teleo_order_docs', doc_ids=document_ids, doc_vecs=document_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016c96f-5296-4ce3-9ec0-c61dd5da3750",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c103ebf-2aab-43b3-859f-e05289a23da8",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using First Group's Teleoscope Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c552d0de-f0f1-47b1-a2ac-555790e3dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('teleo_order_docs.npz')\n",
    "document_ids = loaded['doc_ids'].tolist()\n",
    "document_vectors = loaded['doc_vecs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b78ab-60ad-49a3-8fa7-4b9de0b109eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Append documents in human clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c475f795-f600-4618-b95e-a80caf02b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding group 1\n",
      "Document ids has the shape:  10010\n",
      "Document vectors has the shape:  (10010, 512)\n",
      "\n",
      "Adding group 2\n",
      "Document ids has the shape:  10010\n",
      "Document vectors has the shape:  (10010, 512)\n",
      "\n",
      "Adding group 3\n",
      "Document ids has the shape:  10010\n",
      "Document vectors has the shape:  (10010, 512)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for group in groups:\n",
    "    \n",
    "    # grab latest history item for each group\n",
    "    group_document_ids = group[\"history\"][0][\"included_documents\"]\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    for id in group_document_ids:\n",
    "        \n",
    "        try:\n",
    "            index = document_ids.index(id)\n",
    "            indices.append(index)\n",
    "        \n",
    "        except:\n",
    "            document = db.documents.find_one({\"id\": id}, projection=projection)\n",
    "            document_ids.append(id)\n",
    "            vector = np.array(document[\"textVector\"]).reshape((1, 512))\n",
    "            document_vectors = np.append(document_vectors, vector, axis=0)\n",
    "            \n",
    "            index = document_ids.index(id)\n",
    "            indices.append(index)\n",
    "    i += 1\n",
    "    \n",
    "    print(f'\\nAdding group {i}')\n",
    "    print(\"Document ids has the shape: \", len(document_ids))\n",
    "    print(\"Document vectors has the shape: \", document_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2a7fd-49f4-4880-94e0-68a47c16ccb3",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a11868-4892-426a-be99-3f87806c185b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c760fc67-9fb4-4fc1-a636-3e425816de37",
   "metadata": {},
   "source": [
    "Notes\n",
    "- DR by default hyperparameters\n",
    "- low_memory uses less memory but longer compute time\n",
    "- verbose just logs info\n",
    "\n",
    "TODO\n",
    "- define custom metric\n",
    "- what args are passed to custom metric\n",
    "- how do we check if args are a subset of group?\n",
    "- can we use conditional or do we need matrix\n",
    "\n",
    "ISSUES\n",
    "- general \n",
    "    - how to check if i and j are in the same group\n",
    "    - i and j are vectors\n",
    "    - is it possible to pass i and j as indices instead of vectors?\n",
    "- conditional metric\n",
    "    - groups contain ids\n",
    "    - maybe search for indices of both id and vec then compare? seems expensive\n",
    "    - maybe translate vec to id (or visversa) then compare? seems expensive\n",
    "    - add a new dimension that is the id of vector for easy lookup\n",
    "- matrix metric\n",
    "    - use metric='precomputed'\n",
    "    - expensive as fuck to build matrix\n",
    "    - how to reduce cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4eeec-20b3-4cc4-adaa-4862a594cf23",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Custom Metric"
   ]
  },
  {
   "cell_type": "raw",
   "id": "505df7b9-400f-4060-8e3a-9f64bbe3f6fb",
   "metadata": {},
   "source": [
    "# TODO\n",
    "# add a column to each vector that is the vectors index in document_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52724b5f-d725-443b-8c1d-ffef72687b78",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Organize Document IDs & Indices in Human Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6b9e3293-f871-4166-a1aa-42be119d3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [5630, 7789, 2801, 3965], 1: [10000, 10001, 10002, 10003, 6135, 9393, 10004], 2: [10005, 10006, 10007, 10008, 10009]}\n",
      "{0: ['hetv62', 'lwd55z', 'dhbdpv', 'eyj0sv'], 1: ['g3y7dc', 'j8nzf5', 'fs0vuw', 'q9zlgr', 'ia4w5v', 'ruuxs1', 'hw16a9'], 2: ['mnqbp9', 'spk73c', 'qqwzth', 'dfon3v', 'bqafew']}\n"
     ]
    }
   ],
   "source": [
    "# use dict or ndarray?\n",
    "group_doc_indices = {}\n",
    "group_doc_ids = {}\n",
    "\n",
    "for group in range(len(groups)):\n",
    "    \n",
    "    curr_id = groups[group]['history'][0]['included_documents']\n",
    "    \n",
    "    indices = []\n",
    "    ids = []\n",
    "    \n",
    "    for i in curr_id:\n",
    "        indices.append(document_ids.index(i))\n",
    "        ids.append(i)\n",
    "    \n",
    "    group_doc_indices[group] = indices\n",
    "    group_doc_ids[group] = ids\n",
    "    \n",
    "print(group_doc_indices)\n",
    "print(group_doc_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8128d-9cc6-4c7f-88bb-2057d46160f6",
   "metadata": {},
   "source": [
    "##### Create Distance Matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db481cc6-d511-492b-8218-3aaa427e460d",
   "metadata": {},
   "source": [
    "# using sklean cosine distances\n",
    "dm_cos = cosine_distances(document_vectors)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee022d67-6fb3-45d6-a6b1-c3f90079a157",
   "metadata": {},
   "source": [
    "# using my slow method \n",
    "load_dist_mat = np.load('distance_matrix.npz')\n",
    "my_dm = load_dist_mat['mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c016a88f-8909-4efb-8f42-8df9bbe9b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklean euclidean distances\n",
    "dm = euclidean_distances(document_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705b26c-aa08-4a3e-9c93-af7e88549128",
   "metadata": {},
   "source": [
    "##### Update Distances for Documents within the same human cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f843581-09ad-4a6d-a08f-126b0c7a083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in range(len(groups)):\n",
    "    \n",
    "    docs = groups[group]['history'][0]['included_documents']\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        \n",
    "        index_i = document_ids.index(docs[i])\n",
    "        \n",
    "        for j in range(len(docs)):\n",
    "            \n",
    "            if (i != j):\n",
    "            \n",
    "                index_j = document_ids.index(docs[j])\n",
    "                dm[index_i, index_j] = 0 # 0 if euclidean\n",
    "                dm[index_j, index_i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8fe95e60-a7af-44a3-a710-d84cdb504bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to make sure two docs in the same human cluster are distance 0\n",
    "\n",
    "i = group_doc_indices[0][0]\n",
    "j = group_doc_indices[0][1]\n",
    "dm[i,j] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21407661-f656-4b12-8ea8-185de17acd27",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a243179c-5c48-4e89-a056-75db8213bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leofk/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/umap/umap_.py:1780: UserWarning: using precomputed metric; inverse_transform will be unavailable\n",
      "  warn(\"using precomputed metric; inverse_transform will be unavailable\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(metric='precomputed', n_components=5, verbose=True)\n",
      "Sat Jan 21 21:43:10 2023 Construct fuzzy simplicial set\n",
      "Sat Jan 21 21:43:11 2023 Finding Nearest Neighbors\n",
      "Sat Jan 21 21:43:11 2023 Finished Nearest Neighbor Search\n",
      "Sat Jan 21 21:43:12 2023 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b1520b5f8e47d295226eebda8e1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/200 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 21 21:43:15 2023 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "fitter = umap.UMAP(metric='precomputed', verbose=True, low_memory=True, n_components=5).fit(dm)\n",
    "embedding = fitter.embedding_\n",
    "umap_embeddings = fitter.transform(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "19377dca-e8bf-4338-8d06-ff9789ad2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking to see if similar distances are maintained after reduction\n",
      "\n",
      "Cosine Similarity: 0.9999080300331116\n",
      "Euclidean Distance: 0.1914035677909851\n"
     ]
    }
   ],
   "source": [
    "reduced_i = embedding[5630]\n",
    "reduced_j = embedding[7789]\n",
    "\n",
    "cos = cosine_similarity([red_i],[red_j])[0][0]\n",
    "euc = euclidean_distances([red_i],[red_j])[0][0]\n",
    "print(f'Checking to see if similar distances are maintained after reduction\\n')\n",
    "print(f'Cosine Similarity: {cos}')\n",
    "print(f'Euclidean Distance: {euc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854923fe-c85f-4224-a1bc-18e0fd5df75a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607593d5-4d62-4e0e-b5a4-2fb581188c3b",
   "metadata": {},
   "source": [
    "Notes\n",
    "- Clustering by default hyperparameters\n",
    "- Resultant labels are in the same ordering as data\n",
    "\n",
    "TODO\n",
    "- User parameterize hyperparams\n",
    "- Use custom metric hyperparam here too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "117b726a-f2cc-4589-9c0e-d1da1f495d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN()\n",
    "hdbscan_labels = clusterer.fit_predict(umap_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655a679-ee5d-4707-b7b4-cd8b968dfa5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results\n",
    "Are human clusters maintained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f4b554f2-7aa7-4f62-9b15-cdd4f41b4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array(hdbscan_labels)\n",
    "clusters = {}\n",
    "\n",
    "# iterate over given labels\n",
    "for hdbscan_label in set(hdbscan_labels):\n",
    "        \n",
    "        # find indices of documents for a current label\n",
    "        document_indices_scalar = np.where(label_array == hdbscan_label)[0]\n",
    "        document_indices = [int(i) for i in document_indices_scalar]\n",
    "        \n",
    "        # create list of document ids that are in current label\n",
    "        documents = []\n",
    "        \n",
    "        for i in document_indices:\n",
    "            documents.append(document_ids[i])\n",
    "        \n",
    "        # add label and respective document ids to clusters dictionary\n",
    "        clusters[hdbscan_label] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a5f6ab00-3d68-4233-aefe-0beaf9e2206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, -1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9ba60d93-5701-4086-979d-091f1ad20645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels for group = 0\n",
      "\n",
      "hetv62 158\n",
      "lwd55z 158\n",
      "dhbdpv 158\n",
      "eyj0sv 158\n",
      "\n",
      "Labels for group = 1\n",
      "\n",
      "g3y7dc 153\n",
      "j8nzf5 153\n",
      "fs0vuw 153\n",
      "q9zlgr 153\n",
      "ia4w5v 153\n",
      "ruuxs1 153\n",
      "hw16a9 153\n",
      "\n",
      "Labels for group = 2\n",
      "\n",
      "mnqbp9 150\n",
      "spk73c 150\n",
      "qqwzth 150\n",
      "dfon3v 150\n",
      "bqafew 150\n"
     ]
    }
   ],
   "source": [
    "# examine matchings between human labelled clusters and machine labelled clusters\n",
    "for group in group_doc_indices:\n",
    "    print(f'\\nLabels for group = {group}\\n')\n",
    "    for index in group_doc_indices[group]:\n",
    "        print(document_ids[index], hdbscan_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79dbaa-b19e-4fc0-a647-2a5ce805b5a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Toy Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ea93d60-7e24-4e40-bb4d-0e04ff541181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "4       3450.0  female  2007  \n",
       "5       3650.0    male  2007  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins.csv\")\n",
    "penguins = penguins.dropna()\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64688e69-d536-4d06-acb6-fadca4fe301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89604189,  0.7807321 , -1.42675157, -0.56847478],\n",
       "       [-0.82278787,  0.11958397, -1.06947358, -0.50628618],\n",
       "       [-0.67627982,  0.42472926, -0.42637319, -1.1903608 ],\n",
       "       ...,\n",
       "       [ 1.02687621,  0.52644436, -0.56928439, -0.53738048],\n",
       "       [ 1.24663828,  0.93330475,  0.64546078, -0.13315457],\n",
       "       [ 1.13675725,  0.7807321 , -0.2120064 , -0.53738048]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove categorical features\n",
    "penguin_data = penguins[\n",
    "    [\n",
    "        \"bill_length_mm\",\n",
    "        \"bill_depth_mm\",\n",
    "        \"flipper_length_mm\",\n",
    "        \"body_mass_g\",\n",
    "    ]\n",
    "].values\n",
    "\n",
    "# scaling\n",
    "scaled_penguin_data = StandardScaler().fit_transform(penguin_data)\n",
    "\n",
    "scaled_penguin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4bbcee2-cbd4-478f-b097-acf628785e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89604189,  0.7807321 , -1.42675157, -0.56847478],\n",
       "       [-0.82278787,  0.11958397, -1.06947358, -0.50628618]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1 = scaled_penguin_data[0:2]\n",
    "human_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "528a61a2-d3cb-4c5a-83a5-8ba4cafd1c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaled_penguin_data)\n",
    "type(human_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a7624f-6519-4def-80d6-27d9f968cdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = scaled_penguin_data[0]\n",
    "b = scaled_penguin_data[1]\n",
    "c = scaled_penguin_data[5]\n",
    "\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb74bbd-77f6-4a37-87c8-887d2bbb1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the reduction works, the distance between index 0 and 1 should be 0 \n",
    "a = embedding[0]\n",
    "b = embedding[1]\n",
    "np.dot(a,b)/(norm(a)*norm(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "873bf3bf4ca629f02780c1468f98ab03c421afd8de10b4352774f82eeed6b96f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
