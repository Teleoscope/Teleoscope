{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d979288c-7e14-4d92-b9de-6c2acc9571ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84f9d1b9-d81c-4c83-9c9d-30d03eab859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from bson.objectid import ObjectId\n",
    "import gc\n",
    "import tasks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numba\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, cosine_distances\n",
    "import umap.plot\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import gridfs\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for jupyter notebook widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac8027c-af0d-4bf3-8d06-176ced95da0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['20.220.215.35:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', authmechanism='SCRAM-SHA-256', connecttimeoutms=50000, serverselectiontimeoutms=50000, directconnection=True, replicaset='rs0'), 'aita')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to database\n",
    "db = utils.connect()\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe4861-8e82-4434-b536-fcf9541d0648",
   "metadata": {},
   "source": [
    "### Setup Human Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4448d3-9fca-44af-a4df-16718f686a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 groups from database\n"
     ]
    }
   ],
   "source": [
    "# hardcoded group id strings\n",
    "group_id_strings = ['63901a89e189962b660959cf', '63901a92931eeac91c9924a1', '63901a96e189962b660959d3']\n",
    "\n",
    "# convert to objectId's\n",
    "group_ids = [ObjectId(str(id)) for id in group_id_strings]\n",
    "\n",
    "# retrieve groups from database\n",
    "groups = list(db.groups.find({\"_id\":{\"$in\" : group_ids}}))\n",
    "print(\"Retrieved \" + str(len(groups)) + \" groups from database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8244c486-26d3-409d-b914-30eaec8a44a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hetv62', 'lwd55z', 'dhbdpv', 'eyj0sv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]['history'][0]['included_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c27a74c-e029-40a5-b0ee-c69cd123b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'textVector': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projection here to only include the fields we want\n",
    "projection = {'id': 1, 'textVector': 1}\n",
    "projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74e643-031e-4e66-a2d1-ba5c04f935df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54c336-714e-42b1-94b5-24fe2b2f707e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save & Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415165c7-d80c-4728-b3e2-f6659abe0808",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using First Group's Teleoscope Ordering\n",
    "\n",
    "Change Raw cells below to Code if you need to reload document ids / vectors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0eabfa6c-243a-4e36-ae65-f2af0e9a75a4",
   "metadata": {},
   "source": [
    "# default to ordering documents relative to first group's teleoscope\n",
    "teleoscope_oid = groups[0][\"teleoscope\"]\n",
    "teleoscope_oid"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b83972eb-2932-4801-9936-9353a94fc786",
   "metadata": {
    "tags": []
   },
   "source": [
    "teleoscope = db.teleoscopes.find_one({\"_id\": ObjectId(str(teleoscope_oid))})\n",
    "#teleoscope"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b3894a6-20b1-4156-9fb7-fc9b15382bc1",
   "metadata": {},
   "source": [
    "# saved as ordered_documents.npz\n",
    "# change to code cell if load is needed\n",
    "\n",
    "# get Teleoscope from GridFS\n",
    "all_ordered_documents = utils.gridfsDownload(db, \"teleoscopes\", ObjectId(str(teleoscope[\"history\"][0][\"ranked_document_ids\"])))\n",
    "\n",
    "# np.savez_compressed('all_ordered_documents', ord_docs=all_ordered_documents)\n",
    "# all_ordered_documents = np.load('all_ordered_documents.npz')['ord_docs']\n",
    "\n",
    "len(all_ordered_documents)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdab68b3-ba24-415c-a01b-7bf11fdddac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# grab only subset of the ordered documents\n",
    "limit = 10000\n",
    "# TODO: does this line generate an out of bounds access?\n",
    "ordered_documents = all_ordered_documents[0:limit]\n",
    "limit = min(limit, len(ordered_documents))\n",
    "limit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ff88c0d-2f74-4434-8805-a5d8bf771a38",
   "metadata": {},
   "source": [
    "ordered_documents = all_ordered_documents\n",
    "limit = len(ordered_documents)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab1f7ac9-9c38-4273-bfb9-f2e0933df270",
   "metadata": {},
   "source": [
    "# cursor is a generator which means it yields a new doc one at a time\n",
    "cursor = db.documents.find(\n",
    "    # query\n",
    "    {\"id\":{\"$in\": [document[0] for document in ordered_documents]}},\n",
    "    projection=projection,\n",
    "    # batch size means number of documents at a time taken from MDB, no impact on iteration\n",
    "    batch_size=500\n",
    ")\n",
    "document_ids = []\n",
    "document_vectors = []\n",
    "\n",
    "# for large datasets, this will take a while. Would be better to find out whether the UMAP fns can \n",
    "# accept generators for lazy calculation\n",
    "for document in tqdm.tqdm(cursor, total=limit):\n",
    "    document_ids.append(document[\"id\"])\n",
    "    document_vectors.append(document[\"textVector\"])\n",
    "\n",
    "print(\"There are \" + str(len(document_ids)) + \" document ids.\")\n",
    "print(\"There are \" + str(len(document_vectors)) + \" document vectors.\")\n",
    "\n",
    "np.savez_compressed('teleo_order_docs', doc_ids=document_ids, doc_vecs=document_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975b6eb-51c0-408b-9232-5967aba84cd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Using All Docs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1de2146f-685e-40d1-a064-e757d54777fc",
   "metadata": {},
   "source": [
    "def cacheClusteringData(db):\n",
    "    \"\"\"\n",
    "    Check to see if distance matrix and list of document ids is cached in ~/embeddings\n",
    "    \n",
    "    input:\n",
    "        db: mongoDB connection\n",
    "    output:\n",
    "        dm: distance matrix\n",
    "        ids: list of document ids\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    npzpath = Path('/clustering.npz').expanduser()\n",
    "    \n",
    "    if npzpath.exists():\n",
    "        print(\"Documents have been cached, retrieving now.\")\n",
    "        loaded = np.load(npzpath.as_posix(), allow_pickle=False)\n",
    "        dm = loaded['dist_matrix']\n",
    "        ids = loaded['doc_ids'].tolist()\n",
    "    \n",
    "    else:\n",
    "        print(\"Documents are not cached, building cache now.\")\n",
    "        # db = utils.connect()\n",
    "        allDocuments = utils.getAllDocuments(db, projection={'id':1, 'textVector':1, '_id':0}, batching=True, batchSize=10000)\n",
    "        ids = [x['id'] for x in allDocuments]\n",
    "        print(f'There are {len(ids)} ids in documents.')\n",
    "\n",
    "        vecs = np.array([x['textVector'] for x in allDocuments])\n",
    "        dm = euclidean_distances(vecs)\n",
    "        print(f'The distance matrix has shape: {dm.shape}')\n",
    "\n",
    "        np.savez(npzpath.as_posix(), dist_matrix=dm, doc_ids=ids)\n",
    "    \n",
    "    return dm, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0478269-29ba-494b-85b4-4cae9884c2d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using average teleoscope"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eddf6040-5047-405d-84c5-58d41766c542",
   "metadata": {},
   "source": [
    "npzpath = Path('~/embeddings/embeddings.npz').expanduser()\n",
    "loadDocuments = np.load(npzpath.as_posix(), allow_pickle=False)\n",
    "all_doc_vecs = loadDocuments['documents']\n",
    "\n",
    "pklpath = Path('~/embeddings/ids.pkl').expanduser()\n",
    "with open(pklpath.as_posix(), 'rb') as handle:\n",
    "        all_doc_ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d74bc94-285e-4d17-a04d-f2d834d5db05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this would actually be from ~/embeddings as above\n",
    "loaded = np.load('all_order_docs.npz')\n",
    "all_doc_ids = loaded['doc_ids'].tolist()\n",
    "all_doc_vecs = loaded['doc_vecs']\n",
    "len(all_doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988bd1df-b9f6-41fe-970a-44f8750e8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = min(10000, len(all_doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f23b32-22c9-462c-a31f-4c60ac9a0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "teleo_vecs = []\n",
    "for group in groups:\n",
    "\n",
    "    teleoscope_oid = group[\"teleoscope\"]\n",
    "    teleoscope = db.teleoscopes.find_one({\"_id\": ObjectId(str(teleoscope_oid))})\n",
    "    teleo_vecs.append(teleoscope[\"history\"][0][\"stateVector\"])\n",
    "\n",
    "teleo_vecs = np.array(teleo_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66a4496-001a-40af-b987-aae1d181a10b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleo_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16095cdf-f805-4c3b-adc4-359e7a294634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_vec = np.average(teleo_vecs, axis=0)\n",
    "avg_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36dd8f68-a92f-4712-b4ce-b9d3a6245ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23058389, 0.31979471, 0.30451099, 0.30814943, 0.29490711])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = utils.calculateSimilarity(all_doc_vecs, avg_vec)\n",
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a21e357c-c65d-40d4-a548-f793e54ef28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ia4w5v', 'flo65r', 'sgt76q', 'fzuf7q', 'bqafew']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = utils.rankDocumentsBySimilarity(all_doc_ids, scores)[:limit]\n",
    "document_ids = [i for i, j in ids]\n",
    "document_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "235fdae9-aa30-4e7a-9514-22213b12dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[210153, 156688, 330158, 162159, 43056]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [all_doc_ids.index(i) for i in document_ids]\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3557eddd-3454-43cc-98c6-269831615275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors = np.array([all_doc_vecs[i] for i in indices])\n",
    "document_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016c96f-5296-4ce3-9ec0-c61dd5da3750",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c103ebf-2aab-43b3-859f-e05289a23da8",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using First Group's Teleoscope Ordering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9a3a744-19b9-4b61-b654-15ce11f8377f",
   "metadata": {},
   "source": [
    "loaded = np.load('teleo_order_docs.npz')\n",
    "document_ids = loaded['doc_ids'].tolist()\n",
    "document_vectors = loaded['doc_vecs']\n",
    "len(document_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424b737-865f-40b5-9578-481ca20a91d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Using Entire Set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7214856-e392-4503-8c29-bfba1ed0ac12",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "loaded = np.load('all_order_docs.npz')\n",
    "document_ids = loaded['doc_ids'].tolist()\n",
    "document_vectors = loaded['doc_vecs']\n",
    "len(document_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b78ab-60ad-49a3-8fa7-4b9de0b109eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Append documents in human clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c475f795-f600-4618-b95e-a80caf02b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding group 0\n",
      "Document ids has the shape:  10000\n",
      "Document vectors has the shape:  (10000, 512)\n",
      "\n",
      "Adding group 1\n",
      "Document ids has the shape:  10001\n",
      "Document vectors has the shape:  (10001, 512)\n",
      "\n",
      "Adding group 2\n",
      "Document ids has the shape:  10002\n",
      "Document vectors has the shape:  (10002, 512)\n",
      "{'wifi': [7, 554, 243, 28], 'password': [161, 311, 10000, 474, 0, 73, 89], 'security': [932, 51, 578, 10001, 4]}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "group_doc_indices = {}\n",
    "for group in groups:\n",
    "    \n",
    "    # grab latest history item for each group\n",
    "    group_document_ids = group[\"history\"][0][\"included_documents\"]\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    for id in group_document_ids:\n",
    "        \n",
    "        try:\n",
    "            document_ids.index(id)\n",
    "        \n",
    "        except:\n",
    "            document = db.documents.find_one({\"id\": id}, projection=projection)\n",
    "            document_ids.append(id)\n",
    "            vector = np.array(document[\"textVector\"]).reshape((1, 512))\n",
    "            document_vectors = np.append(document_vectors, vector, axis=0)\n",
    "            \n",
    "        finally:\n",
    "            indices.append(document_ids.index(id))\n",
    "    \n",
    "    group_doc_indices[group[\"history\"][0][\"label\"]] = indices\n",
    "    \n",
    "    print(f'\\nAdding group {i}')\n",
    "    print(\"Document ids has the shape: \", len(document_ids))\n",
    "    print(\"Document vectors has the shape: \", document_vectors.shape)\n",
    "\n",
    "            \n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(group_doc_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2a7fd-49f4-4880-94e0-68a47c16ccb3",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a11868-4892-426a-be99-3f87806c185b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8128d-9cc6-4c7f-88bb-2057d46160f6",
   "metadata": {},
   "source": [
    "##### Create Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c016a88f-8909-4efb-8f42-8df9bbe9b2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 10002)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklean euclidean distances\n",
    "dm = euclidean_distances(document_vectors)\n",
    "dm.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be0a3a62-5f26-42cf-a16b-95a8e0582738",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "loaded = np.load('all_order_docs.npz')\n",
    "document_vectors = loaded['doc_vecs']\n",
    "dm = euclidean_distances(document_vectors)\n",
    "np.savez_compressed('all_docs_dm', dist_mat=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705b26c-aa08-4a3e-9c93-af7e88549128",
   "metadata": {},
   "source": [
    "##### Map 0 Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be3bbb54-c5bc-4377-addf-1a150823d682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wifi': [7, 554, 243, 28],\n",
       " 'password': [161, 311, 10000, 474, 0, 73, 89],\n",
       " 'security': [932, 51, 578, 10001, 4]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_doc_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce6cf17d-e978-4081-9823-99a31e10791b",
   "metadata": {},
   "source": [
    "for group in range(len(groups)):\n",
    "    docs = groups[group]['history'][0]['included_documents']\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        index_i = document_ids.index(docs[i])\n",
    "\n",
    "        for j in range(len(docs)):\n",
    "            index_j = document_ids.index(docs[j])\n",
    "            dm[index_i, index_j] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47a6b556-e95f-4c53-bb57-33b35071c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in group_doc_indices:\n",
    "    \n",
    "    indices = group_doc_indices[group]\n",
    "    size = range(len(indices))\n",
    "\n",
    "    for _i in size:\n",
    "        i = indices[_i]\n",
    "\n",
    "        for _j in size:\n",
    "            j = indices[_j]\n",
    "            dm[i, j] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fe95e60-a7af-44a3-a710-d84cdb504bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to make sure two docs in the same human cluster are distance 0\n",
    "i = group_doc_indices['password'][0]\n",
    "j = group_doc_indices['password'][3]\n",
    "dm[i,j] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21407661-f656-4b12-8ea8-185de17acd27",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a243179c-5c48-4e89-a056-75db8213bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leofk/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/umap/umap_.py:1780: UserWarning: using precomputed metric; inverse_transform will be unavailable\n",
      "  warn(\"using precomputed metric; inverse_transform will be unavailable\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(metric='precomputed', min_dist=0.0, n_components=30, verbose=True)\n",
      "Tue Feb 28 23:23:49 2023 Construct fuzzy simplicial set\n",
      "Tue Feb 28 23:23:49 2023 Finding Nearest Neighbors\n",
      "Tue Feb 28 23:23:50 2023 Finished Nearest Neighbor Search\n",
      "Tue Feb 28 23:23:50 2023 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc53e32f244528a2d9a9e6ef5d188f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/200 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 28 23:23:54 2023 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "umap_embeddings = umap.UMAP(\n",
    "    verbose = True,         # for logging\n",
    "    metric = \"precomputed\", # use distance matrix\n",
    "    n_components = 30,      # reduce to n_components dimensions (2:100)\n",
    "    # n_neighbors = 10,     # local (small n ~2) vs. global (large n ~100) structure \n",
    "    min_dist = 0.0,         # minimum distance apart that points are allowed (0.0:0.99)\n",
    ").fit_transform(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df1e5cf5-97ff-40c6-a4cf-4e1e3b368c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 30)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_embeddings.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b21ff3b-9ea6-4a7b-8109-eaf000f1c53a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# compute inter cluster distances for human groups\n",
    "for group in range(len(groups)):\n",
    "    \n",
    "    docs = groups[group]['history'][0]['included_documents']\n",
    "    print(f'Group {group}')\n",
    "    dst = []\n",
    "    \n",
    "    for i in range(len(docs)):\n",
    "        \n",
    "        index_i = document_ids.index(docs[i])\n",
    "        a = umap_embeddings[index_i]\n",
    "        \n",
    "        for j in range(len(docs)):\n",
    "        \n",
    "            index_j = document_ids.index(docs[j])\n",
    "            b = umap_embeddings[index_j]\n",
    "            euc_a_b = euclidean_distances([a],[b])[0][0]\n",
    "            dst.append(euc_a_b)\n",
    "            # print(f'dist({index_i}, {index_j}) = {euc_a_b}')\n",
    "    \n",
    "    mean = sum(dst) / len(dst)\n",
    "    print(f'AVG Dist = {mean}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854923fe-c85f-4224-a1bc-18e0fd5df75a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "117b726a-f2cc-4589-9c0e-d1da1f495d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Clusters = 52 + outliers\n"
     ]
    }
   ],
   "source": [
    "hdbscan_labels = hdbscan.HDBSCAN(\n",
    "    min_cluster_size = 10,              # n-neighbors needed to be considered a cluster (0:50 df=5)\n",
    "    # min_samples = 5,                  # how conservative clustering will be, larger is more conservative (more outliers) (df=None)\n",
    "    cluster_selection_epsilon = 0.2,    # have large clusters in dense regions while leaving smaller clusters small\n",
    "                                        # merge clusters if inter cluster distance is less than thres (df=0)\n",
    ").fit_predict(umap_embeddings)\n",
    "\n",
    "print(f'Num Clusters = {max(hdbscan_labels)+1} + outliers')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0cab874-a831-4a8f-a490-73aec661c46f",
   "metadata": {},
   "source": [
    "# kmeans for fun \n",
    "kmeans_labels = KMeans(n_clusters=10).fit(umap_embeddings).labels_\n",
    "kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddd2470e-4f42-45c8-90d3-e8dfff440974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels for group = wifi\n",
      "\n",
      "hetv62 38\n",
      "lwd55z 38\n",
      "dhbdpv 38\n",
      "eyj0sv 38\n",
      "\n",
      "Labels for group = password\n",
      "\n",
      "g3y7dc 36\n",
      "j8nzf5 36\n",
      "fs0vuw 36\n",
      "q9zlgr 36\n",
      "ia4w5v 36\n",
      "ruuxs1 36\n",
      "hw16a9 36\n",
      "\n",
      "Labels for group = security\n",
      "\n",
      "mnqbp9 -1\n",
      "spk73c -1\n",
      "qqwzth -1\n",
      "dfon3v -1\n",
      "bqafew -1\n"
     ]
    }
   ],
   "source": [
    "# examine matchings between human labelled clusters and machine labelled clusters\n",
    "for group in group_doc_indices:\n",
    "    print(f'\\nLabels for group = {group}\\n')\n",
    "    for index in group_doc_indices[group]:\n",
    "        print(document_ids[index], hdbscan_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655a679-ee5d-4707-b7b4-cd8b968dfa5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results\n",
    "Are human clusters maintained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91d735b1-5ddf-4be5-a8d5-8c7053339c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wifi': 38, 'password': 36, 'security': -1}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given_labels = {}\n",
    "\n",
    "for group in group_doc_indices:\n",
    "    \n",
    "    labels = hdbscan_labels[group_doc_indices[group]] \n",
    "    correct_label = max(labels)\n",
    "    \n",
    "    if -1 in labels:\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == -1:\n",
    "                index = group_doc_indices[group][i]\n",
    "                hdbscan_labels[index] = correct_label\n",
    "    \n",
    "    given_labels[group] = correct_label\n",
    "               \n",
    "given_labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a5f5857-4a53-4ddb-8add-9976b0dd9285",
   "metadata": {},
   "source": [
    "leo = ObjectId('63868b5fb3cde877de34c27d') \n",
    "paul = ObjectId('637ee569d1259b1565f7e97e') \n",
    "session = ObjectId('63f68cfba7e87c4253864452') \n",
    "\n",
    "userid = leo\n",
    "if db.clusters.count_documents({\"history.user\": userid}, limit=1):\n",
    "    print(f'Clusters for user exists. Delete all.')\n",
    "    db.clusters.delete_many({\"history.user\": userid})\n",
    "print(f'No clusters for user. Ready to populate.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edcbffdf-d791-4373-9ef0-d197234142cd",
   "metadata": {},
   "source": [
    "teleo_oid = ObjectId('63f8fefc2a1c38ea33f6a84a') # telescope 411\n",
    "# teleoscopes.files = {_id: ObjectId('63fe59c54437e8bdaf6655b6')}\n",
    "# teleoscopes_file = ObjectId('63fe59c54437e8bdaf6655b6')\n",
    "\n",
    "namespace = \"teleoscopes\" # teleoscopes.chunks, teleoscopes.files\n",
    "fs = gridfs.GridFS(db)\n",
    "\n",
    "# cluster teleoscope\n",
    "teleo = db.teleoscopes.find_one({\"_id\": teleo_oid})\n",
    "\n",
    "# associated teleoscope.files\n",
    "teleo_file = teleo[\"history\"][0]['ranked_document_ids']\n",
    "\n",
    "# delete telescopes.chunks and teleoscopes.files\n",
    "fs.delete(teleo_file)\n",
    "\n",
    "db.teleoscopes.delete_one({\"_id\": teleo_oid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "704f144e-4e39-485b-8dc5-b47c035097b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = ObjectId('63868b5fb3cde877de34c27d') \n",
    "userid = leo\n",
    "\n",
    "cursor = db.clusters.find(\n",
    "    { \"history.user\" : userid},\n",
    "    projection = {'_id': 1, 'teleoscope': 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64cf5a4e-dcb6-4cb6-b897-efa8fa794d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:00, 184320.00it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_id = []\n",
    "cluster_teleo_id = []\n",
    "\n",
    "for cluster in tqdm.tqdm(cursor):\n",
    "    cluster_id.append(cluster[\"_id\"])\n",
    "    cluster_teleo_id.append(cluster[\"teleoscope\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6fe851f-1a3c-4649-b3cb-d31d469ae152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('63fe59c54437e8bdaf6655b6')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teleo_oid = ObjectId('63fe59c12c22e5451a66548b') # telescope 411\n",
    "teleo = db.teleoscopes.find_one({\"_id\": teleo_oid})\n",
    "teleo_file = teleo[\"history\"][0]['ranked_document_ids']\n",
    "teleo_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4814e6f3-969f-41b2-9619-f30e05545688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg\n"
     ]
    }
   ],
   "source": [
    "orderings = 'AVG'\n",
    "\n",
    "match orderings:\n",
    "    case \"AVG\":\n",
    "        print('avg')\n",
    "    case \"FIRST\":\n",
    "        print('first')\n",
    "    case \"ALL\":\n",
    "        print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f640e00-c519-40f5-8b56-4891c27d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mongodb(db, userid):\n",
    "    \"\"\"\n",
    "    Check to see if user has already built clusters.\n",
    "    If so, need to delete clusters and associated teleoscope items\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    db : \n",
    "        mongoDB connection\n",
    "    userid:\n",
    "        represents ObjectId as str\n",
    "    \"\"\"\n",
    "    namespace = \"teleoscopes\" # teleoscopes.chunks, teleoscopes.files\n",
    "    fs = gridfs.GridFS(db, namespace)\n",
    "\n",
    "    if db.clusters.count_documents(\n",
    "        { \"history.user\": ObjectId(str(userid))}, \n",
    "        limit=1,\n",
    "    ):\n",
    "        \n",
    "        logging.info(f'Clusters for user exists. Delete all.')\n",
    "\n",
    "        cursor = db.clusters.find(\n",
    "            { \"history.user\" : ObjectId(str(userid))},\n",
    "            projection = {'_id': 1, 'teleoscope': 1},\n",
    "        )    \n",
    "\n",
    "        for cluster in tqdm.tqdm(cursor):\n",
    "\n",
    "            # cluster teleoscope\n",
    "            teleo_oid = cluster[\"teleoscope\"]\n",
    "            teleo = db.teleoscopes.find_one({\"_id\": teleo_oid})\n",
    "\n",
    "            # associated teleoscope.files\n",
    "            teleo_file = teleo[\"history\"][0]['ranked_document_ids']\n",
    "\n",
    "            # delete telescopes.chuncks and teleoscopes.files\n",
    "            fs.delete(teleo_file)\n",
    "\n",
    "            # delete teleoscope \n",
    "            db.teleoscopes.delete_one({\"_id\": teleo_oid})\n",
    "\n",
    "            # delete cluster\n",
    "            db.clusters.delete_one({\"_id\": cluster[\"_id\"]})\n",
    "    \n",
    "    \n",
    "    logging.info(f'No clusters for user. Ready to populate.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "55cff93b-ff0d-4678-8098-6b793d3bc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = '63868b5fb3cde877de34c27d'\n",
    "userid = leo\n",
    "clean_mongodb(db, userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "485557c8-5ef2-473d-841b-c114f31ee050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(hdbscan_label, given_labels):\n",
    "    \"\"\"\n",
    "    if -1:              label = 'outliers'   color = #700c1d\n",
    "    if human cluster:   label = human label  color = human color? or #15540d\n",
    "    if machine cluster: label = topic guess  color = #737373\n",
    "\n",
    "    \"\"\"\n",
    "    check = more = False\n",
    "    \n",
    "    if hdbscan_label == -1:\n",
    "        return 'outliers', '#700c1d'\n",
    "\n",
    "    for _name in given_labels:\n",
    "\n",
    "        label = given_labels[_name]\n",
    "        \n",
    "        if (hdbscan_label == label):\n",
    "            if more:\n",
    "                name += \" & \" + _name\n",
    "            else:\n",
    "                name = _name\n",
    "                more = check = True\n",
    "    \n",
    "    if check:\n",
    "        return name, '#15540d'\n",
    "\n",
    "    return 'machine', '#737373'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ff67f2b-e76c-4129-aee9-72754122d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b2c020b-ac95-454b-af14-278c2074ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(label_ids):\n",
    "    \n",
    "    docs = [] \n",
    "    \n",
    "    label_ids = label_ids.tolist()\n",
    "    cursor = db.documents.find({\"id\":{\"$in\": label_ids}})\n",
    "\n",
    "    for document in tqdm.tqdm(cursor):\n",
    "        docs.append(document[\"text\"])\n",
    "        \n",
    "    docs_pp = [preprocess(text) for text in nlp.pipe(docs)]\n",
    "\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    vec = CountVectorizer(stop_words='english')\n",
    "    X = vec.fit_transform(docs_pp)\n",
    "\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=1, learning_method=\"batch\", max_iter=10\n",
    "    )\n",
    "    \n",
    "    document_topics = lda.fit_transform(X)\n",
    "    sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "    feature_names = np.array(vec.get_feature_names_out())\n",
    "    \n",
    "    return feature_names[sorting[0][0]] + \" \" + feature_names[sorting[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d910e6b2-59e8-48aa-83db-a30e6f805095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code by Dr. Varada Kolhatkar adapted from cpsc330\n",
    "def preprocess(\n",
    "    doc,\n",
    "    min_token_len=2,\n",
    "    irrelevant_pos=[\"ADV\", \"PRON\", \"CCONJ\", \"PUNCT\", \"PART\", \"DET\", \"ADP\", \"SPACE\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Given text, min_token_len, and irrelevant_pos carry out preprocessing of the text\n",
    "    and return a preprocessed string.\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    doc : (spaCy doc object)\n",
    "        the spacy doc object of the text\n",
    "    min_token_len : (int)\n",
    "        min_token_length required\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant pos tags\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (str) the preprocessed text\n",
    "    \"\"\"\n",
    "\n",
    "    clean_text = []\n",
    "\n",
    "    for token in doc:\n",
    "        if (\n",
    "            token.is_stop == False  # Check if it's not a stopword\n",
    "            and len(token) > min_token_len  # Check if the word meets minimum threshold\n",
    "            and token.pos_ not in irrelevant_pos\n",
    "        ):  # Check if the POS is in the acceptable POS tags\n",
    "            lemma = token.lemma_  # Take the lemma of the word\n",
    "            clean_text.append(lemma.lower())\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43884d33-3826-4188-bdd0-9acdc143e543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:54, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [104], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmachine\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;28mlen\u001b[39m(label_ids))\n\u001b[0;32m---> 23\u001b[0m     _label \u001b[38;5;241m=\u001b[39m \u001b[43mget_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# add label and respective document ids to clusters dictionary\u001b[39;00m\n\u001b[1;32m     26\u001b[0m clusters[_label] \u001b[38;5;241m=\u001b[39m documents\n",
      "Cell \u001b[0;32mIn [102], line 8\u001b[0m, in \u001b[0;36mget_topic\u001b[0;34m(label_ids)\u001b[0m\n\u001b[1;32m      5\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m label_ids\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m cursor \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39mfind({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$in\u001b[39m\u001b[38;5;124m\"\u001b[39m: label_ids}})\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(cursor):\n\u001b[1;32m      9\u001b[0m     docs\u001b[38;5;241m.\u001b[39mappend(document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m docs_pp \u001b[38;5;241m=\u001b[39m [preprocess(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe(docs)]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/cursor.py:1248\u001b[0m, in \u001b[0;36mCursor.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__empty:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/cursor.py:1165\u001b[0m, in \u001b[0;36mCursor._refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidOperation(\n\u001b[1;32m   1144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhint\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is required when using the min/max query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m option to ensure the query utilizes the correct index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m         )\n\u001b[1;32m   1147\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_class(\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_flags,\n\u001b[1;32m   1149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__collection\u001b[38;5;241m.\u001b[39mdatabase\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__exhaust,\n\u001b[1;32m   1164\u001b[0m     )\n\u001b[0;32m-> 1165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__id:  \u001b[38;5;66;03m# Get More\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__limit:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/cursor.py:1052\u001b[0m, in \u001b[0;36mCursor.__send_message\u001b[0;34m(self, operation)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidOperation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexhaust cursors do not support auto encryption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unpack_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__address\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01min\u001b[39;00m _CURSOR_CLOSED_ERRORS \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__exhaust:\n\u001b[1;32m   1057\u001b[0m         \u001b[38;5;66;03m# Don't send killCursors because the cursor is already closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/_csot.py:105\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/mongo_client.py:1330\u001b[0m, in \u001b[0;36mMongoClient._run_operation\u001b[0;34m(self, operation, unpack_res, address)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     operation\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Reset op in case of retry.\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m server\u001b[38;5;241m.\u001b[39mrun_operation(\n\u001b[1;32m   1327\u001b[0m         sock_info, operation, read_preference, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_listeners, unpack_res\n\u001b[1;32m   1328\u001b[0m     )\n\u001b[0;32m-> 1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retryable_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/_csot.py:105\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/mongo_client.py:1448\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m last_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m last_error\n\u001b[0;32m-> 1448\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retrying:\n\u001b[1;32m   1451\u001b[0m         \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m         \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m         \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/mongo_client.py:1326\u001b[0m, in \u001b[0;36mMongoClient._run_operation.<locals>._cmd\u001b[0;34m(session, server, sock_info, read_preference)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cmd\u001b[39m(session, server, sock_info, read_preference):\n\u001b[1;32m   1325\u001b[0m     operation\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Reset op in case of retry.\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_listeners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_res\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/server.py:115\u001b[0m, in \u001b[0;36mServer.run_operation\u001b[0;34m(self, sock_info, operation, read_preference, listeners, unpack_res)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     sock_info\u001b[38;5;241m.\u001b[39msend_message(data, max_doc_size)\n\u001b[0;32m--> 115\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43msock_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Unpack and check for command errors.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cmd:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/pool.py:821\u001b[0m, in \u001b[0;36mSocketInfo.receive_message\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m receive_message(\u001b[38;5;28mself\u001b[39m, request_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_message_size)\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_connection_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/pool.py:819\u001b[0m, in \u001b[0;36mSocketInfo.receive_message\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m\"\"\"Receive a raw BSON message or raise ConnectionFailure.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \n\u001b[1;32m    816\u001b[0m \u001b[38;5;124;03mIf any exception is raised, the socket is closed.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreceive_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_message_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_connection_failure(error)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/network.py:217\u001b[0m, in \u001b[0;36mreceive_message\u001b[0;34m(sock_info, request_id, max_message_size)\u001b[0m\n\u001b[1;32m    214\u001b[0m         deadline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Ignore the response's request id.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m length, _, response_to, op_code \u001b[38;5;241m=\u001b[39m _UNPACK_HEADER(\n\u001b[0;32m--> 217\u001b[0m     \u001b[43m_receive_data_on_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# No request_id for exhaust cursor \"getMore\".\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/pymongo/network.py:299\u001b[0m, in \u001b[0;36m_receive_data_on_socket\u001b[0;34m(sock_info, length, deadline)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _csot\u001b[38;5;241m.\u001b[39mget_timeout():\n\u001b[1;32m    298\u001b[0m         sock_info\u001b[38;5;241m.\u001b[39mset_socket_timeout(\u001b[38;5;28mmax\u001b[39m(deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic(), \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 299\u001b[0m     chunk_length \u001b[38;5;241m=\u001b[39m \u001b[43msock_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbytes_read\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BLOCKING_IO_ERRORS:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimed out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clusters = {}\n",
    "\n",
    "for hdbscan_label in set(hdbscan_labels):\n",
    "        \n",
    "        # array of indices of documents with current hdbscan label\n",
    "        document_indices_array = np.where(hdbscan_labels == hdbscan_label)[0]\n",
    "        \n",
    "        # all document_ids as array\n",
    "        ids = np.array(document_ids)\n",
    "        \n",
    "        # array of ids of documents with current hdbscan label \n",
    "        label_ids = ids[document_indices_array]\n",
    "\n",
    "        # create list of document ids that are in current hdbscan label\n",
    "        documents = label_ids.tolist()\n",
    "        \n",
    "        # create appropriate label for current hdbscan label\n",
    "        _label, _color = get_label(hdbscan_label, given_labels)\n",
    "        \n",
    "        # learn a topic label for machine clusters\n",
    "        if _label == 'machine':\n",
    "            limit = min(20, len(label_ids))\n",
    "            _label = get_topic(label_ids[:limit])\n",
    "        \n",
    "        # add label and respective document ids to clusters dictionary\n",
    "        clusters[_label] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea6155-58ca-4df7-8603-f50b0ee73323",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dac6068f-de82-4218-aeb7-115fd8b9f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7f2ed-ff3c-4834-9d13-af0877255cdf",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7115fe00-d884-42ce-958f-8dbfd8119806",
   "metadata": {},
   "source": [
    "mapper = umap.UMAP(\n",
    "    verbose = True,         # for logging\n",
    "    # metric = \"precomputed\", # use distance matrix\n",
    "    n_components = 2,      # reduce to n_components dimensions (2:100)\n",
    "    # n_neighbors = 10,     # local (small n ~2) vs. global (large n ~100) structure \n",
    "    min_dist = 0.0,         # minimum distance apart that points are allowed (0.0:0.99)\n",
    ").fit(umap_embeddings)\n",
    "twod_umap = mapper.transform(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ced8a1-d0a5-43e2-8710-63c8ae76c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "twod_umap = umap.UMAP(\n",
    "    verbose = True,         # for logging\n",
    "    metric = \"precomputed\", # use distance matrix\n",
    "    n_components = 2,      # reduce to n_components dimensions (2:100)\n",
    "    # n_neighbors = 10,     # local (small n ~2) vs. global (large n ~100) structure \n",
    "    min_dist = 0.0,         # minimum distance apart that points are allowed (0.0:0.99)\n",
    ").fit_transform(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648d100-77bb-421a-9009-c8d161365b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=10,            # num of neighbouring points needed to be considered a cluster\n",
    "    min_samples=None,               # how conservative clustering will be. larger is more conservative.\n",
    "    cluster_selection_epsilon=0.2,   # what it means for points to be close\n",
    ").fit(twod_umap)\n",
    "\n",
    "# hdbscan_labels = hdbscan.HDBSCAN(\n",
    "#     min_cluster_size=10,            # num of neighbouring points needed to be considered a cluster\n",
    "#     min_samples=None,               # how conservative clustering will be. larger is more conservative.\n",
    "#     cluster_selection_epsilon=0.2,   # what it means for points to be close\n",
    "# ).fit_predict(twod_umap)\n",
    "\n",
    "print(f'Num Clusters = {max(hdbscan_labels)+1} + outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920224af-f335-451b-a201-45861d569a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.single_linkage_tree_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d4a32-4402-47fc-ba72-620de17e0713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap.plot.points(mapper, labels=hdbscan_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77ebfe-bc1e-45db-a023-da87aeaf51dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mallard] *",
   "language": "python",
   "name": "conda-env-mallard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "873bf3bf4ca629f02780c1468f98ab03c421afd8de10b4352774f82eeed6b96f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
